{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp regress_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11556\\883215780.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "#|export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split #, RandomizedSearchCVcore\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from ML_projects import const_vals as CONST\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpl_patches\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "class TrainRegression():\n",
    "       \n",
    "       def __init__(self,\n",
    "               df_path : str , # path to dataframe to be used to train. File should be CSV file\n",
    "               requested_model : str , # model to train. Options : 'RFR' 'XGB' 'SVR' 'RIDGE' 'KNEIGHBORS' 'GRADIENT_BOOST' 'ADA'\n",
    "               ground_truth_col: str, # name of the column with true data to train\n",
    "               test_size : float , #size of data to be used for test \n",
    "               hyper_method : str , #hyperparameter tunning method. accepts : 'randomized' 'bayesian' , 'bayesian continous'\n",
    "               columns_to_remove : list[str]=None , #columns not to use for trainning the model. These columns will be removed.\n",
    "               ):\n",
    "             self.df_path = df_path\n",
    "             self.columns_to_remove = columns_to_remove\n",
    "             self.ground_truth_col = ground_truth_col\n",
    "             self.test_size = test_size\n",
    "             self.hyper_method = hyper_method\n",
    "             self.model_str = requested_model\n",
    "             self.model_name = requested_model\n",
    "\n",
    "\n",
    "             #load data and get train test data\n",
    "             self.x_train, self.x_test, self.y_train, self.y_test = self._load_df_split_data()\n",
    "             \n",
    "             # create initial model and match the params \n",
    "\n",
    "             self.model , self.params = self._match_models_()\n",
    "\n",
    "             #hyperparameter tunning\n",
    "             self.best_params = self.hyperparameter()\n",
    "\n",
    "             #train best model \n",
    "\n",
    "             self.best_model = self._create_best_model()\n",
    "\n",
    "             #fit model\n",
    "\n",
    "             self.best_model.fit(self.x_train, self.y_train)\n",
    "\n",
    "             # Model evaluation\n",
    "             self.evaluate_model()\n",
    "       \n",
    "\n",
    "       def _match_models_(self):\n",
    "            self.model = CONST.algorithm_to_model[self.model_str]\n",
    "            self.params = CONST.algorithm_to_params[self.model_str]\n",
    "\n",
    "            return self.model , self.params\n",
    "\n",
    "       def _load_df_split_data(self):\n",
    "               \n",
    "               self.df = pd.read_csv(self.df_path)\n",
    "               #load dataframe\n",
    "               if self.columns_to_remove!= None:\n",
    "                     self.df = self.df.drop(self.columns_to_remove,axis=1)\n",
    "          \n",
    "               # split to x,y and train test data\n",
    "               self.x = self.df.drop(self.ground_truth_col,axis=1)\n",
    "               self.y = self.df[self.ground_truth_col].values\n",
    "\n",
    "               #split data to train and test\n",
    "               self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "                      self.x, self.y, test_size=self.test_size, random_state=42)\n",
    "\n",
    "               return self.x_train, self.x_test, self.y_train, self.y_test\n",
    "       \n",
    "\n",
    "       def hyperparameter(self):\n",
    "             if self.hyper_method == 'randomized':\n",
    "                   rf_random = RandomizedSearchCV(estimator = self.model, \n",
    "                                                  param_distributions = self.params,\n",
    "                                                  n_iter = CONST.N_ITERATIONS_RFR,\n",
    "                                                  cv = CONST.CV_RFR, \n",
    "                                                  verbose=CONST.VERBOSE , \n",
    "                                                  random_state=CONST.RANDOM_STATE , \n",
    "                                                  n_jobs = CONST.N_JOBS)\n",
    "                   \n",
    "                   #fit model \n",
    "                   rf_random.fit(self.x_train, self.y_train)\n",
    "\n",
    "                  #best params\n",
    "                   self.best_params = rf_random.best_params_\n",
    "\n",
    "\n",
    "             elif self.hyper_method == 'bayesian':\n",
    "                  rf_bayes = BayesSearchCV(self.model,\n",
    "                                           search_spaces=self.params, \n",
    "                                           n_iter=CONST.N_ITERATIONS_RFR, \n",
    "                                           cv=CONST.CV_RFR)\n",
    "                  np.int = int\n",
    "      \n",
    "                  #fit model \n",
    "                  rf_bayes.fit(self.x_train, self.y_train)\n",
    "\n",
    "                  self.best_params = rf_bayes.best_params_\n",
    "\n",
    "                  print(f'best params : {rf_bayes.best_params_}')\n",
    "\n",
    "\n",
    "             return self.best_params\n",
    "       \n",
    "       def _create_best_model(self):\n",
    "             if self.model_str == 'RFR':\n",
    "                   self.best_model = RandomForestRegressor(**self.best_params)\n",
    "            \n",
    "             elif self.model_str == 'XGB':\n",
    "                   self.best_model =xgb.XGBRegressor(**self.best_params)\n",
    "             \n",
    "             elif self.model_str == 'SVR':\n",
    "                   self.best_model = SVR(**self.best_params)\n",
    "\n",
    "             elif self.model_str == 'RIDGE':\n",
    "                   self.best_model = Ridge(**self.best_params)\n",
    "            \n",
    "             elif self.model_str == 'KNEIGHBORS':\n",
    "                   self.best_model = KNeighborsRegressor(**self.best_params)\n",
    "\n",
    "             elif self.model_str == 'GRADIENT_BOOST':\n",
    "                   self.best_model = GradientBoostingRegressor(**self.best_params)\n",
    "\n",
    "             elif self.model_str == 'ADA':\n",
    "                   self.best_model = AdaBoostRegressor(**self.best_params)\n",
    "\n",
    "             return self.best_model\n",
    "       \n",
    "       def evaluate_model(self):\n",
    "             \n",
    "            # Make predictions\n",
    "            y_pred = self.best_model.predict(self.x_test)\n",
    "\n",
    "            # Calculate R2 score\n",
    "            r2 = r2_score(self.y_test, y_pred)\n",
    "\n",
    "            # Calculate MAE\n",
    "            mae = mean_absolute_error(self.y_test, y_pred)\n",
    "\n",
    "            # Calculate MSE\n",
    "            mse = mean_squared_error(self.y_test, y_pred)\n",
    "\n",
    "            # Calculate RMSE\n",
    "            rmse = np.sqrt(mse)\n",
    "\n",
    "            # Calculate MAPE\n",
    "            mape = np.mean(np.abs((self.y_test - y_pred) / self.y_test)) * 100\n",
    "\n",
    "            # Plotting predictions vs. ground truth\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.scatter(self.y_test, y_pred, color='blue', alpha=0.5)\n",
    "            plt.plot([self.y_test.min(), self.y_test.max()], [self.y_test.min(), self.y_test.max()], 'k--', lw=2)\n",
    "            plt.xlabel('Actual')\n",
    "            plt.ylabel('Predicted')\n",
    "            plt.title(f'Actual vs. Predicted - {self.model_name}')\n",
    "            plt.grid(True)\n",
    "\n",
    "\n",
    "                        # create a list with two empty handles (or more if needed)\n",
    "            handles = [mpl_patches.Rectangle((0, 0), 1, 1, fc=\"white\", ec=\"white\", \n",
    "                                          lw=0, alpha=0)] * 2\n",
    "\n",
    "            # create the corresponding number of labels (= the text you want to display)\n",
    "            labels = []\n",
    "            labels.append(\"R2 = {0:.4g}\".format(r2))\n",
    "            labels.append(\"MAE = {0:.4g}\".format(mae))\n",
    "            labels.append(\"MAE = {0:.4g}\".format(rmse))\n",
    "\n",
    "            plt.legend(handles, labels, loc='best', fontsize='small', \n",
    "                       fancybox=True, framealpha=0.7, \n",
    "                       handlelength=0, handletextpad=0)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            # Print evaluation metrics\n",
    "            print(\"R2 Score:\", r2)\n",
    "            print(\"Mean Absolute Error:\", mae)\n",
    "            print(\"Mean Squared Error:\", mse)\n",
    "            print(\"Root Mean Squared Error:\", rmse)\n",
    "            print(\"Mean Absolute Percentage Error:\", mape)\n",
    "\n",
    "            # #feature importance\n",
    "            # importance_scores = self.best_model.feature_importances_\n",
    "            # feature_names = self.x_test.columns.tolist()\n",
    "\n",
    "            #       # Plot feature importance\n",
    "            # plt.figure(figsize=(10, 6))\n",
    "            # plt.barh(feature_names, importance_scores)\n",
    "            # plt.xlabel(f'Feature Importance Score - {self.model_name} ')\n",
    "            # plt.ylabel('Features')\n",
    "            # plt.title('Feature Importance')\n",
    "            # plt.show()\n",
    "\n",
    "                  \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "UsageError",
     "evalue": "Current task already created and requested project name 'test clearML1' does not match current project name 'test_clearML'. If you wish to create additional tasks use `Task.create`, or close the current task with `task.close()` before calling `Task.init(...)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUsageError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m instance \u001b[38;5;241m=\u001b[39m \u001b[43mTrainRegression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mgit\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mML_projects\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mnbs\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mresampled_sen2_v2.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[43mrequested_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRFR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mground_truth_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTOC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43mcolumns_to_remove\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0.1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0.2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43mhyper_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbayesian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m    \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 21\u001b[0m, in \u001b[0;36mTrainRegression.__init__\u001b[1;34m(self, df_path, requested_model, ground_truth_col, test_size, hyper_method, columns_to_remove)\u001b[0m\n\u001b[0;32m     18\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m requested_model\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Initialize ClearML\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[43mTask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest clearML1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Log hyperparameters\u001b[39;00m\n\u001b[0;32m     24\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39madd_parameters({\n\u001b[0;32m     25\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_path\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_path,\n\u001b[0;32m     26\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequested_model\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_str,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns_to_remove\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns_to_remove\n\u001b[0;32m     31\u001b[0m  })\n",
      "File \u001b[1;32md:\\git\\ML_projects\\.venv\\Lib\\site-packages\\clearml\\task.py:498\u001b[0m, in \u001b[0;36mTask.init\u001b[1;34m(cls, project_name, task_name, task_type, tags, reuse_last_task_id, continue_last_task, output_uri, auto_connect_arg_parser, auto_connect_frameworks, auto_resource_monitoring, auto_connect_streams, deferred_init)\u001b[0m\n\u001b[0;32m    495\u001b[0m         BackgroundMonitor\u001b[38;5;241m.\u001b[39mstart_all(task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__main_task)\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m running_remotely():\n\u001b[1;32m--> 498\u001b[0m         \u001b[43mverify_defaults_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__main_task\n\u001b[0;32m    502\u001b[0m is_sub_process_task_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\git\\ML_projects\\.venv\\Lib\\site-packages\\clearml\\task.py:459\u001b[0m, in \u001b[0;36mTask.init.<locals>.verify_defaults_match\u001b[1;34m()\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m field, default, current \u001b[38;5;129;01min\u001b[39;00m validate:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m default \u001b[38;5;241m!=\u001b[39m current:\n\u001b[1;32m--> 459\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UsageError(\n\u001b[0;32m    460\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent task already created \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand requested \u001b[39m\u001b[38;5;132;01m{field}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{default}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not match current \u001b[39m\u001b[38;5;132;01m{field}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{current}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you wish to create additional tasks use `Task.create`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    463\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor close the current task with `task.close()` before calling `Task.init(...)`\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    464\u001b[0m                 field\u001b[38;5;241m=\u001b[39mfield,\n\u001b[0;32m    465\u001b[0m                 default\u001b[38;5;241m=\u001b[39mdefault,\n\u001b[0;32m    466\u001b[0m                 current\u001b[38;5;241m=\u001b[39mcurrent,\n\u001b[0;32m    467\u001b[0m             )\n\u001b[0;32m    468\u001b[0m         )\n",
      "\u001b[1;31mUsageError\u001b[0m: Current task already created and requested project name 'test clearML1' does not match current project name 'test_clearML'. If you wish to create additional tasks use `Task.create`, or close the current task with `task.close()` before calling `Task.init(...)`"
     ]
    }
   ],
   "source": [
    "instance = TrainRegression(\n",
    "  df_path=r\"D:\\git\\ML_projects\\nbs\\data\\resampled_sen2_v2.csv\",\n",
    "  requested_model= 'RFR',\n",
    "  ground_truth_col = \"TOC\",\n",
    "  test_size = 0.25,\n",
    "  columns_to_remove = ['Unnamed: 0.1','Unnamed: 0.2', 'Unnamed: 0', 'Lon', 'Lat', 'NI'],\n",
    "  hyper_method = 'bayesian'    \n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = TrainRegression(\n",
    "  df_path=r\"D:\\git\\ML_projects\\nbs\\data\\resampled_sen2_v2.csv\",\n",
    "  requested_model= 'XGB',\n",
    "  ground_truth_col = \"TOC\",\n",
    "  test_size = 0.25,\n",
    "  columns_to_remove = ['Unnamed: 0.1','Unnamed: 0.2', 'Unnamed: 0', 'Lon', 'Lat', 'NI'],\n",
    "  hyper_method = 'bayesian'    \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance = TrainRegression(\n",
    "#   df_path=r\"D:\\git\\ML_projects\\nbs\\data\\resampled_sen2_v2.csv\",\n",
    "#   requested_model= 'SVR',\n",
    "#   ground_truth_col = \"TOC\",\n",
    "#   test_size = 0.25,\n",
    "#   columns_to_remove = ['Unnamed: 0.1', 'Unnamed: 0', 'Lon', 'Lat', 'NI'],\n",
    "#   hyper_method = 'bayesian'    \n",
    "#   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = TrainRegression(\n",
    "  df_path=r\"D:\\git\\ML_projects\\nbs\\data\\resampled_sen2_v2.csv\",\n",
    "  requested_model= 'RIDGE',\n",
    "  ground_truth_col = \"TOC\",\n",
    "  test_size = 0.25,\n",
    "  columns_to_remove = ['Unnamed: 0.1','Unnamed: 0.2', 'Unnamed: 0', 'Lon', 'Lat', 'NI'],\n",
    "  hyper_method = 'bayesian'    \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = TrainRegression(\n",
    "  df_path=r\"D:\\git\\ML_projects\\nbs\\data\\resampled_sen2_v2.csv\",\n",
    "  requested_model= 'KNEIGHBORS',\n",
    "  ground_truth_col = \"TOC\",\n",
    "  test_size = 0.25,\n",
    "  columns_to_remove = ['Unnamed: 0.1','Unnamed: 0.2', 'Unnamed: 0', 'Lon', 'Lat', 'NI'],\n",
    "  hyper_method = 'bayesian'    \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = TrainRegression(\n",
    "  df_path=r\"D:\\git\\ML_projects\\nbs\\data\\resampled_sen2_v2.csv\",\n",
    "  requested_model= 'GRADIENT_BOOST',\n",
    "  ground_truth_col = \"TOC\",\n",
    "  test_size = 0.25,\n",
    "  columns_to_remove = ['Unnamed: 0.1','Unnamed: 0.2', 'Unnamed: 0', 'Lon', 'Lat', 'NI'],\n",
    "  hyper_method = 'bayesian'    \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = TrainRegression(\n",
    "  df_path=r\"D:\\git\\ML_projects\\nbs\\data\\resampled_sen2_v2.csv\",\n",
    "  requested_model= 'ADA',\n",
    "  ground_truth_col = \"TOC\",\n",
    "  test_size = 0.25,\n",
    "  columns_to_remove = ['Unnamed: 0.1','Unnamed: 0.2', 'Unnamed: 0', 'Lon', 'Lat', 'NI'],\n",
    "  hyper_method = 'bayesian'    \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = TrainRegression(\n",
    "  df_path=r\"D:\\git\\ML_projects\\nbs\\data\\resampled_sen2.csv\",\n",
    "  requested_model= 'RFR',\n",
    "  ground_truth_col = \"TOC\",\n",
    "  test_size = 0.25,\n",
    "  columns_to_remove = ['Unnamed: 0.1', 'Unnamed: 0', 'Lon', 'Lat', 'clay', 'silt','sand', 'NI'],\n",
    "  hyper_method = 'bayesian'    \n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = TrainRegression(\n",
    "  df_path=r\"D:\\git\\ML_projects\\nbs\\data\\resampled_sen2.csv\",\n",
    "  requested_model= 'XGB',\n",
    "  ground_truth_col = \"TOC\",\n",
    "  test_size = 0.25,\n",
    "  columns_to_remove = ['Unnamed: 0.1', 'Unnamed: 0', 'Lon', 'Lat', 'clay', 'silt','sand', 'NI'],\n",
    "  hyper_method = 'bayesian'    \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = TrainRegression(\n",
    "  df_path=r\"D:\\git\\ML_projects\\nbs\\data\\resampled_sen2.csv\",\n",
    "  requested_model= 'KNEIGHBORS',\n",
    "  ground_truth_col = \"TOC\",\n",
    "  test_size = 0.25,\n",
    "  columns_to_remove = ['Unnamed: 0.1', 'Unnamed: 0', 'Lon', 'Lat', 'clay', 'silt','sand', 'NI'],\n",
    "  hyper_method = 'bayesian'    \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
