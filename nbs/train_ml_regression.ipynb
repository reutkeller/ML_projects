{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp regress_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from skopt import BayesSearchCV\n",
    "from ML_projects import const_vals as CONST\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "class TrainRegression():\n",
    "       \n",
    "       def __init__(self,\n",
    "               df_path : str , # path to dataframe to be used to train. File should be CSV file\n",
    "               requested_model : str , # model to train. Options : 'RFR' 'XGB' 'SVR' 'RIDGE' 'KNEIGHBORS' 'GRADIENT_BOOST' 'ADA'\n",
    "               ground_truth_col: str, # name of the column with true data to train\n",
    "               test_size : float , #size of data to be used for test \n",
    "               hyper_method : str , #hyperparameter tunning method. accepts : 'randomized' 'bayesian' , 'bayesian continous'\n",
    "               columns_to_remove : list[str]=None , #columns not to use for trainning the model. These columns will be removed.\n",
    "              #  hyper_params : dict = CONST.RANDOM_GRID_RFR, #parameters for hyperparameter tunning\n",
    "              #  space : list = CONST.SPACE_RFR  , #\n",
    "               ):\n",
    "             self.df_path = df_path\n",
    "             self.columns_to_remove = columns_to_remove\n",
    "             self.ground_truth_col = ground_truth_col\n",
    "             self.test_size = test_size\n",
    "             self.hyper_method = hyper_method\n",
    "             self.model_str = requested_model\n",
    "\n",
    "             #load data and get train test data\n",
    "             self.x_train, self.x_test, self.y_train, self.y_test = self._load_df_split_data()\n",
    "             \n",
    "             # create initial model and match the params \n",
    "\n",
    "             self.model , self.params = self._match_models_()\n",
    "\n",
    "             #hyperparameter tunning\n",
    "             self.best_params = self.hyperparameter()\n",
    "\n",
    "             #train best model \n",
    "\n",
    "             self.best_model = self._create_best_model()\n",
    "\n",
    "             #fit model\n",
    "\n",
    "             self.best_model.fit(self.x_train, self.y_train)\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "       def _match_models_(self):\n",
    "            self.model = CONST.algorithm_to_model[self.model_str]\n",
    "            self.params = CONST.algorithm_to_params[self.model_str]\n",
    "\n",
    "            return self.model , self.params\n",
    "\n",
    "       def _load_df_split_data(self):\n",
    "               \n",
    "               self.df = pd.read_csv(self.df_path)\n",
    "               #load dataframe\n",
    "               if self.columns_to_remove!= None:\n",
    "                     self.df = self.df.drop(self.columns_to_remove,axis=1)\n",
    "          \n",
    "               # split to x,y and train test data\n",
    "               self.x = self.df.drop(self.ground_truth_col,axis=1)\n",
    "               self.y = self.df[self.ground_truth_col].values\n",
    "\n",
    "               #split data to train and test\n",
    "               self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "                      self.x, self.y, test_size=self.test_size, random_state=42)\n",
    "\n",
    "               return self.x_train, self.x_test, self.y_train, self.y_test\n",
    "       \n",
    "\n",
    "       def hyperparameter(self):\n",
    "             if self.hyper_method == 'randomized':\n",
    "                   rf_random = RandomizedSearchCV(estimator = self.model, \n",
    "                                                  param_distributions = self.params,\n",
    "                                                  n_iter = CONST.N_ITERATIONS_RFR,\n",
    "                                                  cv = CONST.CV_RFR, \n",
    "                                                  verbose=CONST.VERBOSE , \n",
    "                                                  random_state=CONST.RANDOM_STATE , \n",
    "                                                  n_jobs = CONST.N_JOBS)\n",
    "                   \n",
    "                   #fit model \n",
    "                   rf_random.fit(self.x_train, self.y_train)\n",
    "\n",
    "                  #best params\n",
    "                   self.best_params = rf_random.best_params_\n",
    "\n",
    "\n",
    "             elif self.hyper_method == 'bayesian':\n",
    "                  rf_bayes = BayesSearchCV(self.model,\n",
    "                                           search_spaces=self.params, \n",
    "                                           n_iter=CONST.N_ITERATIONS_RFR, \n",
    "                                           cv=CONST.CV_RFR)\n",
    "                  np.int = int\n",
    "      \n",
    "                  #fit model \n",
    "                  rf_bayes.fit(self.x_train, self.y_train)\n",
    "\n",
    "                  self.best_params = rf_bayes.best_params_\n",
    "\n",
    "                  print(f'best params : {rf_bayes.best_params_}')\n",
    "\n",
    "\n",
    "             return self.best_params\n",
    "       \n",
    "       def _create_best_model(self):\n",
    "             if self.model_str == 'RFR':\n",
    "                   self.best_model = RandomForestRegressor(**self.best_params)\n",
    "            \n",
    "             elif self.model_str == 'XGB':\n",
    "                   self.best_model =xgb.XGBRegressor(**self.best_params)\n",
    "             \n",
    "             elif self.model_str == 'SVR':\n",
    "                   self.best_model = SVR(**self.best_params)\n",
    "\n",
    "             elif self.model_str == 'RIDGE':\n",
    "                   self.best_model = Ridge(**self.best_params)\n",
    "            \n",
    "             elif self.model_str == 'KNEIGHBORS':\n",
    "                   self.best_model = KNeighborsRegressor(**self.best_params)\n",
    "\n",
    "             elif self.model_str == 'GRADIENT_BOOST':\n",
    "                   self.best_model = GradientBoostingRegressor(**self.best_params)\n",
    "\n",
    "             elif self.model_str == 'ADA':\n",
    "                   self.best_model = AdaBoostRegressor(**self.best_params)\n",
    "\n",
    "             return self.best_model\n",
    "       \n",
    "       def evaluate_model(self):\n",
    "             print('not written yet')\n",
    "\n",
    "                   \n",
    "              \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TrainRegression' object has no attribute 'hyper_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m instance \u001b[38;5;241m=\u001b[39m \u001b[43mTrainRegression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mgit\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mML_projects\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mnbs\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mresampled_sen2.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[43mrequested_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRFR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mground_truth_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTOC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43mcolumns_to_remove\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0.1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msilt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43mhyper_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbayesian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m    \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# test = instance.the_best_model\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# print(instance.the_best_params)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 29\u001b[0m, in \u001b[0;36mTrainRegression.__init__\u001b[1;34m(self, df_path, requested_model, ground_truth_col, test_size, hyper_method, columns_to_remove)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_models_()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#hyperparameter tunning\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#train best model \u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_best_model()\n",
      "Cell \u001b[1;32mIn[8], line 85\u001b[0m, in \u001b[0;36mTrainRegression.hyperparameter\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_params \u001b[38;5;241m=\u001b[39m rf_random\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyper_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbayesian\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     84\u001b[0m      rf_bayes \u001b[38;5;241m=\u001b[39m BayesSearchCV(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m---> 85\u001b[0m                               search_spaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyper_params\u001b[49m, \n\u001b[0;32m     86\u001b[0m                               n_iter\u001b[38;5;241m=\u001b[39mCONST\u001b[38;5;241m.\u001b[39mN_ITERATIONS_RFR, \n\u001b[0;32m     87\u001b[0m                               cv\u001b[38;5;241m=\u001b[39mCONST\u001b[38;5;241m.\u001b[39mCV_RFR)\n\u001b[0;32m     88\u001b[0m      np\u001b[38;5;241m.\u001b[39mint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m\n\u001b[0;32m     90\u001b[0m      \u001b[38;5;66;03m#fit model \u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TrainRegression' object has no attribute 'hyper_params'"
     ]
    }
   ],
   "source": [
    "instance = TrainRegression(\n",
    "  df_path=r\"D:\\git\\ML_projects\\nbs\\data\\resampled_sen2.csv\",\n",
    "  requested_model= 'RFR',\n",
    "  ground_truth_col = \"TOC\",\n",
    "  test_size = 0.25,\n",
    "  columns_to_remove = ['Unnamed: 0.1', 'Unnamed: 0', 'Lon', 'Lat', 'clay', 'silt','sand', 'NI'],\n",
    "  hyper_method = 'bayesian'    \n",
    "  )\n",
    "\n",
    "\n",
    "# test = instance.the_best_model\n",
    "# print(instance.the_best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
