{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp regress_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split #, RandomizedSearchCVcore\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from ML_projects import const_vals as CONST\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "class TrainRegression():\n",
    "       \n",
    "       def __init__(self,\n",
    "               df_path : str , # path to dataframe to be used to train. File should be CSV file\n",
    "               requested_model : str , # model to train. Options : 'RFR' 'XGB' 'SVR' 'RIDGE' 'KNEIGHBORS' 'GRADIENT_BOOST' 'ADA'\n",
    "               ground_truth_col: str, # name of the column with true data to train\n",
    "               test_size : float , #size of data to be used for test \n",
    "               hyper_method : str , #hyperparameter tunning method. accepts : 'randomized' 'bayesian' , 'bayesian continous'\n",
    "               columns_to_remove : list[str]=None , #columns not to use for trainning the model. These columns will be removed.\n",
    "               ):\n",
    "             self.df_path = df_path\n",
    "             self.columns_to_remove = columns_to_remove\n",
    "             self.ground_truth_col = ground_truth_col\n",
    "             self.test_size = test_size\n",
    "             self.hyper_method = hyper_method\n",
    "             self.model_str = requested_model\n",
    "\n",
    "             #load data and get train test data\n",
    "             self.x_train, self.x_test, self.y_train, self.y_test = self._load_df_split_data()\n",
    "             \n",
    "             # create initial model and match the params \n",
    "\n",
    "             self.model , self.params = self._match_models_()\n",
    "\n",
    "             #hyperparameter tunning\n",
    "             self.best_params = self.hyperparameter()\n",
    "\n",
    "             #train best model \n",
    "\n",
    "             self.best_model = self._create_best_model()\n",
    "\n",
    "             #fit model\n",
    "\n",
    "             self.best_model.fit(self.x_train, self.y_train)\n",
    "\n",
    "             # Model evaluation\n",
    "             self.evaluate_model()\n",
    "       \n",
    "\n",
    "       def _match_models_(self):\n",
    "            self.model = CONST.algorithm_to_model[self.model_str]\n",
    "            self.params = CONST.algorithm_to_params[self.model_str]\n",
    "\n",
    "            return self.model , self.params\n",
    "\n",
    "       def _load_df_split_data(self):\n",
    "               \n",
    "               self.df = pd.read_csv(self.df_path)\n",
    "               #load dataframe\n",
    "               if self.columns_to_remove!= None:\n",
    "                     self.df = self.df.drop(self.columns_to_remove,axis=1)\n",
    "          \n",
    "               # split to x,y and train test data\n",
    "               self.x = self.df.drop(self.ground_truth_col,axis=1)\n",
    "               self.y = self.df[self.ground_truth_col].values\n",
    "\n",
    "               #split data to train and test\n",
    "               self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "                      self.x, self.y, test_size=self.test_size, random_state=42)\n",
    "\n",
    "               return self.x_train, self.x_test, self.y_train, self.y_test\n",
    "       \n",
    "\n",
    "       def hyperparameter(self):\n",
    "             if self.hyper_method == 'randomized':\n",
    "                   rf_random = RandomizedSearchCV(estimator = self.model, \n",
    "                                                  param_distributions = self.params,\n",
    "                                                  n_iter = CONST.N_ITERATIONS_RFR,\n",
    "                                                  cv = CONST.CV_RFR, \n",
    "                                                  verbose=CONST.VERBOSE , \n",
    "                                                  random_state=CONST.RANDOM_STATE , \n",
    "                                                  n_jobs = CONST.N_JOBS)\n",
    "                   \n",
    "                   #fit model \n",
    "                   rf_random.fit(self.x_train, self.y_train)\n",
    "\n",
    "                  #best params\n",
    "                   self.best_params = rf_random.best_params_\n",
    "\n",
    "\n",
    "             elif self.hyper_method == 'bayesian':\n",
    "                  rf_bayes = BayesSearchCV(self.model,\n",
    "                                           search_spaces=self.params, \n",
    "                                           n_iter=CONST.N_ITERATIONS_RFR, \n",
    "                                           cv=CONST.CV_RFR)\n",
    "                  np.int = int\n",
    "      \n",
    "                  #fit model \n",
    "                  rf_bayes.fit(self.x_train, self.y_train)\n",
    "\n",
    "                  self.best_params = rf_bayes.best_params_\n",
    "\n",
    "                  print(f'best params : {rf_bayes.best_params_}')\n",
    "\n",
    "\n",
    "             return self.best_params\n",
    "       \n",
    "       def _create_best_model(self):\n",
    "             if self.model_str == 'RFR':\n",
    "                   self.best_model = RandomForestRegressor(**self.best_params)\n",
    "            \n",
    "             elif self.model_str == 'XGB':\n",
    "                   self.best_model =xgb.XGBRegressor(**self.best_params)\n",
    "             \n",
    "             elif self.model_str == 'SVR':\n",
    "                   self.best_model = SVR(**self.best_params)\n",
    "\n",
    "             elif self.model_str == 'RIDGE':\n",
    "                   self.best_model = Ridge(**self.best_params)\n",
    "            \n",
    "             elif self.model_str == 'KNEIGHBORS':\n",
    "                   self.best_model = KNeighborsRegressor(**self.best_params)\n",
    "\n",
    "             elif self.model_str == 'GRADIENT_BOOST':\n",
    "                   self.best_model = GradientBoostingRegressor(**self.best_params)\n",
    "\n",
    "             elif self.model_str == 'ADA':\n",
    "                   self.best_model = AdaBoostRegressor(**self.best_params)\n",
    "\n",
    "             return self.best_model\n",
    "       \n",
    "       def evaluate_model(self):\n",
    "             \n",
    "            # Make predictions\n",
    "            y_pred = self.best_model.predict(self.x_test)\n",
    "\n",
    "            # Calculate R2 score\n",
    "            r2 = r2_score(self.y_test, y_pred)\n",
    "\n",
    "            # Calculate MAE\n",
    "            mae = mean_absolute_error(self.y_test, y_pred)\n",
    "\n",
    "            # Calculate MSE\n",
    "            mse = mean_squared_error(self.y_test, y_pred)\n",
    "\n",
    "            # Calculate RMSE\n",
    "            rmse = np.sqrt(mse)\n",
    "\n",
    "            # Calculate MAPE\n",
    "            mape = np.mean(np.abs((self.y_test - y_pred) / self.y_test)) * 100\n",
    "\n",
    "            # Plotting predictions vs. ground truth\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.scatter(self.y_test, y_pred, color='blue', alpha=0.5)\n",
    "            plt.plot([self.y_test.min(), self.y_test.max()], [self.y_test.min(), self.y_test.max()], 'k--', lw=2)\n",
    "            plt.xlabel('Actual')\n",
    "            plt.ylabel('Predicted')\n",
    "            plt.title('Actual vs. Predicted')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "            # Print evaluation metrics\n",
    "            print(\"R2 Score:\", r2)\n",
    "            print(\"Mean Absolute Error:\", mae)\n",
    "            print(\"Mean Squared Error:\", mse)\n",
    "            print(\"Root Mean Squared Error:\", rmse)\n",
    "            print(\"Mean Absolute Percentage Error:\", mape)\n",
    "\n",
    "\n",
    "                  \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = TrainRegression(\n",
    "  df_path=r\"D:\\git\\ML_projects\\nbs\\data\\resampled_sen2.csv\",\n",
    "  requested_model= 'RFR',\n",
    "  ground_truth_col = \"TOC\",\n",
    "  test_size = 0.25,\n",
    "  columns_to_remove = ['Unnamed: 0.1', 'Unnamed: 0', 'Lon', 'Lat', 'clay', 'silt','sand', 'NI'],\n",
    "  hyper_method = 'bayesian'    \n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = TrainRegression(\n",
    "  df_path=r\"D:\\git\\ML_projects\\nbs\\data\\resampled_sen2.csv\",\n",
    "  requested_model= 'XGB',\n",
    "  ground_truth_col = \"TOC\",\n",
    "  test_size = 0.25,\n",
    "  columns_to_remove = ['Unnamed: 0.1', 'Unnamed: 0', 'Lon', 'Lat', 'clay', 'silt','sand', 'NI'],\n",
    "  hyper_method = 'bayesian'    \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
