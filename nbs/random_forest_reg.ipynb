{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp rf_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from skopt import BayesSearchCV,gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from ML_projects import const_vals as CONST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class TrainRFReg():\n",
    "  def __init__(self,\n",
    "      train_test_data : list , # list with train/test data , in this order : [x_train,x_test,y_train,y_test]\n",
    "      hyper_method : str , #hyperparameter tunning method. accepts : 'randomized' 'bayesian' , 'bayesian continous'\n",
    "      hyper_params : dict = CONST.RANDOM_GRID_RFR , #parameters for hyperparameter tunning\n",
    "      space : list = CONST.SPACE_RFR , #space for continues bayesian continous search \n",
    "      ):\n",
    "     self.hyper_method = hyper_method\n",
    "     self.hyper_params = hyper_params\n",
    "\n",
    "     self.x_train = train_test_data[0]\n",
    "     self.x_test = train_test_data[1]\n",
    "     self.y_train = train_test_data[2]\n",
    "     self.y_test = train_test_data[3]\n",
    "     \n",
    "     # space for bayesian continous searching\n",
    "     self.space = space\n",
    "\n",
    "     #generate random forest regressor \n",
    "     self.model = RandomForestRegressor()\n",
    "\n",
    "\n",
    "     self.best_params = self.hyperparameter()\n",
    "\n",
    "  def objective(self):\n",
    "    '''\n",
    "    Scitkit Learn Optimize requires an objective function to minimize.\n",
    "    We use the average of cross-validation mean absolute errors as \n",
    "    the objective function (also called cost function in optimization)\n",
    "    '''\n",
    "    self.model.set_params(**self.hyper_params)\n",
    "\n",
    "    return -np.mean(cross_val_score(self.model, self.x_train, \n",
    "                                    self.y_train, \n",
    "                                    cv=CONST.CV_RFR, \n",
    "                                    n_jobs=CONST.N_JOBS,\n",
    "                                    scoring=\"neg_mean_absolute_error\"))\n",
    "\n",
    "\n",
    "\n",
    "  def hyperparameter(self):\n",
    "     \n",
    "     if self.hyper_method == 'randomized':\n",
    "       \n",
    "       rf_random = RandomizedSearchCV(estimator = self.model, \n",
    "                                      param_distributions = self.hyper_params,\n",
    "                                      n_iter = CONST.N_ITERATIONS_RFR,\n",
    "                                      cv = CONST.CV_RFR, \n",
    "                                      verbose=CONST.VERBOSE , \n",
    "                                      random_state=CONST.RANDOM_STATE , \n",
    "                                      n_jobs = CONST.N_JOBS)\n",
    "       \n",
    "       #fit model \n",
    "       rf_random.fit(self.x_train, self.y_train)\n",
    "\n",
    "       #best params\n",
    "       self.best_params = rf_random.best_params_\n",
    "\n",
    "\n",
    "     elif self.hyper_method == 'bayesian':\n",
    "      \n",
    "      rf_bayes = BayesSearchCV(self.model,\n",
    "                      search_spaces=self.hyper_params, \n",
    "                      n_iter=CONST.N_ITERATIONS_RFR, \n",
    "                      cv=CONST.CV_RFR)\n",
    "      np.int = int\n",
    "      \n",
    "       #fit model \n",
    "      rf_bayes.fit(self.x_train, self.y_train)\n",
    "\n",
    "      self.best_params = rf_bayes.best_params_\n",
    "\n",
    "     elif self.hyper_method == 'bayesian continous':\n",
    "\n",
    "\n",
    "      self.best_params = gp_minimize(self.objective, \n",
    "                                     dimension = list(CONST.SPACE_RFR.keys()),\n",
    "                                     space = CONST.SPACE_RFR, \n",
    "                                     n_calls=CONST.N_CALLS, \n",
    "                                     random_state=CONST.RANDOM_STATE)\n",
    "\n",
    "     return self.best_params\n",
    "       \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bootstrap',\n",
       " 'max_depth',\n",
       " 'max_features',\n",
       " 'min_samples_leaf',\n",
       " 'min_samples_split',\n",
       " 'n_estimators']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(CONST.SPACE_RFR.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "      #  def train_model(self):\n",
    "      #         # create base model\n",
    "      #         rf = RandomForestRegressor()\n",
    "\n",
    "      #         rf_random = RandomizedSearchCV(estimator = rf, \n",
    "      #                                        param_distributions = CONST.random_grid_rf,\n",
    "      #                                          n_iter = CONST.n_iteration_rf,\n",
    "      #                                            cv = CONST.cv_rf, \n",
    "      #                                            verbose=CONST.VERBOSE , \n",
    "      #                                            random_state=CONST.RANDOM_STATE , \n",
    "      #                                            n_jobs = CONST.N_JOBS)\n",
    "  \n",
    "      #           # Fit the random search model\n",
    "      #         rf_random.fit(self.x_train, self.y_train)\n",
    "              \n",
    "      #         #train model \n",
    "      #         self.best_rf_params = rf_random.best_params_\n",
    "\n",
    "      #         #fit best model\n",
    "      #         self.rf_model = RandomForestRegressor(**self.best_rf_params)\n",
    "\n",
    "      #         self.rf_model.fit(self.x_train,self.y_train)\n",
    "      #         #predict\n",
    "\n",
    "      #         y_pred = self.rf_model.predict(self.x_test)\n",
    "\n",
    "      #         self.r2 = r2_score(y_pred, self.y_test)\n",
    "\n",
    "\n",
    "\n",
    "      #         return self.rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
