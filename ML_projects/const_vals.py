# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/CONSTANTS.ipynb.

# %% auto 0
__all__ = ['RANDOM_STATE', 'N_JOBS', 'VERBOSE', 'N_ITERATIONS_RFR', 'CV_RFR', 'N_CALLS', 'RANDOM_GRID_RFR', 'SPACE_RFR',
           'RANDOM_GRID_XGB', 'RANDOM_GRID_SVR', 'RANDOM_RIDGE_REGRESSION', 'RANDOM_KNEIGHBORSR_REGRESSION',
           'RANDOM_GRADIENT_BOOST_REGRESSION', 'RANDOM_ADA_BOOST_REGRESSION']

# %% ../nbs/CONSTANTS.ipynb 3
import numpy as np
from skopt.space import Real, Categorical, Integer
from skopt.utils import use_named_args
from sklearn.model_selection import cross_val_score


# %% ../nbs/CONSTANTS.ipynb 4
RANDOM_STATE = 42 
N_JOBS = -1 
VERBOSE = 1

# %% ../nbs/CONSTANTS.ipynb 5
N_ITERATIONS_RFR = 100
CV_RFR = 3
N_CALLS = 20


# %% ../nbs/CONSTANTS.ipynb 6
RANDOM_GRID_RFR={'bootstrap': [True, False],
                'max_depth': [3,10, 25, 45, 70],
                'max_features': ['sqrt', 'log2'],
                'min_samples_leaf': [1, 2, 4],
                'min_samples_split': [2, 5, 10],
                'n_estimators': [200, 400, 600, 800]}

SPACE_RFR = {'bootstrap' : Categorical([True, False]),
             'max_depth' : Integer(1,100),
             'max_features' : Categorical(['sqrt', 'log2']),
             'min_samples_leaf': Integer(1,5),
             'min_samples_split' : Integer(1,10),
             'n_estimators' : Integer(100,800)}


RANDOM_GRID_XGB = {
    "n_estimators": [10, 50, 100],
    "subsample":[0.6, 0.8, 1],
    "learning_rate":[0.01, 0.1, 0.5, 1],
    "gamma":[0.01, 0.1, 1, 5],
    "colsample_bytree":[0.5, 0.7, 0.9, 1],
    "alpha":[0, 0.1, 0.5]
}


RANDOM_GRID_SVR = {
    "kernel" : ["linear","sigmoid","poly"],
    "degree" : [2,3,5,7],
    "gamma" : ["scale","auto"],
    "epsilon" : [0.1 , 0.5 , 0.9]
    }

RANDOM_RIDGE_REGRESSION = {
  "alpha" : [1,3,5],
  "solver" : ["auto","svd","cholesky","sag"]
  }

RANDOM_KNEIGHBORSR_REGRESSION = {
  "n_neighbors" : [3,5,7,9],
  "weights" : ["uniform","distance"],
  "algorithm" : ["auto"],
  }

RANDOM_GRADIENT_BOOST_REGRESSION = {
  "loss" : ["squared_error", "absolute_error", "huber", "quantile"],
  "learning_rate":[0.01, 0.1, 0.5, 1],
  "n_estimators": [200, 400, 600, 800],
  'min_samples_split': [2, 5, 10],
  'max_depth': [3,10, 25, 45, 70],
  'max_features': ['sqrt', 'log2'],
  }

RANDOM_ADA_BOOST_REGRESSION={
  "n_estimators": [200, 400, 600, 800],
  "learning_rate":[0.01, 0.1, 0.5, 1],
  "loss" : ["linear", "square", "exponential"]
  }





